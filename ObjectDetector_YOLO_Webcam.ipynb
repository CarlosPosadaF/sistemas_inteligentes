{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CGVQ53KfEl0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-G6Tb-2sYGe"
      },
      "source": [
        "# Demo de Ejecución Yolo\n",
        "**Propuesta para trabajo final, asignatura: SISTEMAS INTELIGENTE, Facultad de Minas, Universidad Nacional de Colombia, Medellín**\n",
        "\n",
        "A continuación podra ejecutar Yolo (You Look Only Once), en su equipo personal , utilizando la plataforma Colab de google y aprovechando  los servicios de procesamiento e inclusive GPU. Adicionalmente podrá interactuar con su cámara Web, para verificar el reconocmiento de objetos en tiempo real. Tenga en cuenta que el proceso depende altamente de la capacidad de ancho de banda de conexión a Internet. El código está debidamente documentado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nddL3NW31CK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26e7206-429f-441f-afcd-6e1a2e965f4c"
      },
      "source": [
        "!git clone https://github.com/..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLO-Object-Detection'...\n",
            "remote: Enumerating objects: 30, done.\u001b[K\n",
            "remote: Total 30 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (30/30), 12.60 MiB | 13.60 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tP_xUspJaK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c23ab60-bb5f-4458-bb28-3be3fafb7b04"
      },
      "source": [
        "%cd YOLO-Object-Detection//yolo-object-detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLO-Object-Detection/yolo-object-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS917czhWi7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821be7e0-38af-440b-8e82-9af96d3cae9f"
      },
      "source": [
        "!wget \"https://pjreddie.com/media/files/yolov3.weights\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-24 01:33:13--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   105MB/s    in 2.2s    \n",
            "\n",
            "2023-05-24 01:33:15 (105 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qRaZzSDKZe1"
      },
      "source": [
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX9Voz5VKaHi"
      },
      "source": [
        "yoloPath=\"yolo-coco\"\n",
        "#yolo --ruta base al directorio YOLO\n",
        "#confidence --probabilidad mínima de filtrar las detecciones débiles\n",
        "#threshold --umbral al aplicar supresión no máxima\n",
        "args={'yolo': yoloPath , 'confidence': 0.5, 'threshold': 0.3}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0MSlvBYKfPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2f56c9-1b87-4f3c-e601-51f03f644fc2"
      },
      "source": [
        "# cargar las etiquetas de la clase COCO en las que se entrenó nuestro modelo YOLO\n",
        "LABELS = open(yoloPath+\"//coco.names\").read().strip().split(\"\\n\")\n",
        "print(\"Toal classes {0}\".format(len(LABELS)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toal classes 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjfwpEsIKjsD"
      },
      "source": [
        "# inicializar una lista de colores para representar cada etiqueta de clase posible\n",
        "np.random.seed(42)\n",
        "# crear una lista aleatoria de números de tipo entero en el rango 0-255. Tamaño = len (ETIQUETAS), 3... 3 para RGB\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEW-O_kKkq0"
      },
      "source": [
        "# derivar las rutas a los pesos YOLO y configuración del modelo\n",
        "weightsPath = \"yolov3.weights\"\n",
        "configPath = yoloPath+\"//yolov3.cfg\"\n",
        "# cargar nuestro detector de objetos YOLO entrenado en el conjunto de datos COCO (80 clases)\n",
        "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u301D1WbKmu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f84b548-ad55-453e-b74e-3c6420a48a76"
      },
      "source": [
        "#Generalmente en una red secuencial de CNN solo habrá una capa de salida al final.\n",
        "#En la arquitectura YOLO v3 estamos utilizando múltiples capas de salida que dan predicciones.\n",
        "ln_all = net.getLayerNames()\n",
        "\n",
        "ln=[]\n",
        "# determinar solo los nombres de capa *salida* que necesitamos de YOLO\n",
        "for i in ln_all:\n",
        "    if \"yolo\" in i:\n",
        "        ln.append(i)\n",
        "\n",
        "print(ln)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yolo_82', 'yolo_94', 'yolo_106']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9DHf_wqp6or"
      },
      "source": [
        "'''\n",
        "## Camera Capture\n",
        "Usar una cámara web para capturar imágenes para procesarlas en tiempo de ejecución.\n",
        "Fuente: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n",
        "'''\n",
        "\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      // mostrar el vídeo en el elemento HTML\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Cambie el tamaño de la salida para que se ajuste al elemento de vídeo.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // imprime los registros en la celda\n",
        "      let jsLog = function(abc) {\n",
        "        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n",
        "      }\n",
        "\n",
        "      // Espere a que se haga clic en Capture.\n",
        "      // Esperar new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      for (let i = 0; i < 5; i++) {\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        img = canvas.toDataURL('image/jpeg', quality);\n",
        "\n",
        "        // mostrar cada imagen capturada\n",
        "        jsLog(i + \"sending\")\n",
        "        // Llame a una función python y envíe esta imagen\n",
        "        google.colab.kernel.invokeFunction('notebook.run_algo', [img], {});\n",
        "        jsLog(i + \"SENT\")\n",
        "\n",
        "        // esperar X milisegundos, antes de la próxima captura\n",
        "        await new Promise(resolve => setTimeout(resolve, 250));\n",
        "      }\n",
        "\n",
        "      stream.getVideoTracks()[0].stop(); // stop video stream\n",
        "    }\n",
        "    ''')\n",
        "  display(js) # hacer el HTML proporcionado, parte de la celda\n",
        "  data = eval_js('takePhoto({})'.format(quality)) # Llamar la función Javascript takePhoto()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCHdTb7h7R8_"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import time\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import logging\n",
        "\n",
        "\n",
        "def data_uri_to_img(uri):\n",
        "    \"\"\"convert base64image to numpy array\"\"\"\n",
        "    try:\n",
        "        image = base64.b64decode(uri.split(',')[1], validate=True)\n",
        "        # hacer la imagen binaria, una imagen PIL\n",
        "        image = Image.open(BytesIO(image))\n",
        "        # Convertir a un array numpy\n",
        "        image = np.array(image, dtype=np.uint8);\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        logging.exception(e);\n",
        "        print('\\n')\n",
        "        return None\n",
        "\n",
        "\n",
        "def run_algo(imgB64):\n",
        "    \"\"\"\n",
        "    in Colab, run_algo function gets invoked by the JavaScript, that sends N images every second\n",
        "\n",
        "    params:\n",
        "      image: image\n",
        "    \"\"\"\n",
        "    image = data_uri_to_img(imgB64)\n",
        "    frame = image\n",
        "    if image is None:\n",
        "        print(\"At run_algo(): image is None.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Detección de ejecuciones\n",
        "        frame = imutils.resize(frame, width=400)\n",
        "        (H, W) = frame.shape[:2]\n",
        "        blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "        net.setInput(blob)\n",
        "        # realizar un pase hacia delante del detector de objetos YOLO, dándonos nuestras cajas delimitadoras y las probabilidades asociadas\n",
        "        layerOutputs = net.forward(ln)\n",
        "\n",
        "        # YOLO ahora ha procesado nuestra imagen y obtuvo los datos. ahora solo tenemos que recuperar esos datos\n",
        "        # inicializar listas vacías\n",
        "        boxes = []\n",
        "        confidences = []\n",
        "        classIDs = []\n",
        "\n",
        "        # Vamos a empezar a rellenar estas listas con datos de nuestro YOLO layerOutputs\n",
        "        # Bucle sobre cada una de las salidas de capa\n",
        "        for output in layerOutputs:\n",
        "            # bucle sobre cada una de las detecciones\n",
        "            for detection in output:\n",
        "                # extraer el ID de clase y la confianza (es decir, probabilidad) de la detección de objetos actuales\n",
        "                scores = detection[5:]\n",
        "                classID = np.argmax(scores)\n",
        "                confidence = scores[classID]\n",
        "\n",
        "                # filtrar las predicciones débiles asegurando que la probabilidad detectada es mayor que la probabilidad mínima\n",
        "                if confidence > args[\"confidence\"]:\n",
        "                    # escalar las coordenadas del cuadro delimitador en relación con el tamaño de la imagen\n",
        "                    # YOLO devuelve el centro (x, y)-coordenadas del cuadro delimitador seguido de la anchura y altura del cuadro\n",
        "                    box = detection[0:4] * np.array([W, H, W, H])\n",
        "\n",
        "                    # convertir valores de caja a valores internos\n",
        "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "                    # Usar las coordenadas (x, y)-coordinates para derivar la esquina superior izquierda del cuadro delimitador\n",
        "                    x = int(centerX - (width / 2))\n",
        "                    y = int(centerY - (height / 2))\n",
        "\n",
        "                    # actualizar nuestra lista de coordenadas, confidencias e identificadores de clase\n",
        "                    boxes.append([x, y, int(width), int(height)])\n",
        "                    confidences.append(float(confidence))\n",
        "                    classIDs.append(classID)\n",
        "\n",
        "\n",
        "            # Aplicar función non-maxima suppression (NMSBoxes()) para suprimir las cajas de límites débiles y superpuestas\n",
        "            # Todo lo que se requiere es que presentemos los siguientes valores:\n",
        "            # bounding boxes , confidences , confidence threshold and NMS threshold\n",
        "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, args[\"confidence\"], args[\"threshold\"])\n",
        "\n",
        "        # idxs ahora mantenga los índices después de supresión no máxima\n",
        "\n",
        "        # dibujar los cuadros y el texto de la clase en el marco\n",
        "        if len(idxs) > 0:\n",
        "            for i in idxs.flatten():\n",
        "                # extraer las coordenadas de la caja delimitadora\n",
        "                (x, y) = (boxes[i][0], boxes[i][1])  # x,y--coordinate of top left corner\n",
        "                (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "                # Elegir el color\n",
        "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "\n",
        "                # dibujar un rectángulo de caja delimitadora\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)  # 2 is the line thickness\n",
        "\n",
        "                # Preparar el texto\n",
        "                text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
        "\n",
        "                # Poner texto en la imagen en x, y-5....un poco arriba de la caja\n",
        "                cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        cv2_imshow(frame)\n",
        "    except Exception as e:\n",
        "        logging.exception(e)\n",
        "\n",
        "# registrar esta función, por lo que el código JS podría llamar a este\n",
        "output.register_callback('notebook.run_algo', run_algo)\n",
        "\n",
        "# poner el código JS en la celda y ejecutarlo\n",
        "take_photo()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1P54mCp-3Ru"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}